{"cells":[{"cell_type":"markdown","metadata":{"id":"gGiw79_dvMj0"},"source":["## NLP, gradio and huggingface environment"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":13084,"status":"ok","timestamp":1720689878875,"user":{"displayName":"abbas khan","userId":"07434490259532895643"},"user_tz":-300},"id":"kbwwyHV5vM-s"},"outputs":[],"source":["!pip install transformers datasets evaluate accelerate gradio "]},{"cell_type":"markdown","metadata":{"id":"O35u_SDA0459"},"source":["## Text Summrization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"96g3XqJw1ZGs"},"outputs":[],"source":["from transformers import pipeline\n","\n","get_completion = pipeline(\"summarization\", model=\"shleifer/distilbart-cnn-12-6\")\n","\n","def summarize(input):\n","    output = get_completion(input)\n","    return output[0]['summary_text']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g2DMhtW61cEc"},"outputs":[],"source":["text = ('''The tower is 324 metres (1,063 ft) tall, about the same height\n","        as an 81-storey building, and the tallest structure in Paris.\n","        Its base is square, measuring 125 metres (410 ft) on each side.\n","        During its construction, the Eiffel Tower surpassed the Washington\n","        Monument to become the tallest man-made structure in the world,\n","        a title it held for 41 years until the Chrysler Building\n","        in New York City was finished in 1930. It was the first structure\n","        to reach a height of 300 metres. Due to the addition of a broadcasting\n","        aerial at the top of the tower in 1957, it is now taller than the\n","        Chrysler Building by 5.2 metres (17 ft). Excluding transmitters, the\n","        Eiffel Tower is the second tallest free-standing structure in France\n","        after the Millau Viaduct.''')"]},{"cell_type":"markdown","metadata":{"id":"p-mfcUK5uxw2"},"source":["# Text Classification"]},{"cell_type":"markdown","metadata":{"id":"VVRZBlwWvBND"},"source":["Text classification is a common NLP task that assigns a label or class to text. Some of the largest companies run text classification in production for a wide range of practical applications. One of the most popular forms of text classification is sentiment analysis, which assigns a label like üôÇ positive, üôÅ negative, or üòê neutral to a sequence of text.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"osndRtyCvYOc"},"source":["### Load IMDb dataset\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b_BJyNHSvZU8"},"outputs":[],"source":["from datasets import load_dataset\n","\n","imdb = load_dataset(\"imdb\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lyRZV3TovcFH"},"outputs":[],"source":["imdb[\"test\"][0]"]},{"cell_type":"markdown","metadata":{"id":"qnpG3LXovee7"},"source":["There are two fields in this dataset:\n","\n","* text: the movie review text.\n","\n","* label: a value that is either 0 for a negative review or 1 for a positive review."]},{"cell_type":"markdown","metadata":{"id":"DbluCJ3kvrIs"},"source":["### Preprocess\n","The next step is to load a DistilBERT tokenizer to preprocess the text field:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0RVPCODNvq_N"},"outputs":[],"source":["from transformers import AutoTokenizer\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")"]},{"cell_type":"markdown","metadata":{"id":"_XJ0QA-pvvd8"},"source":["Create a preprocessing function to tokenize text and truncate sequences to be no longer than DistilBERT‚Äôs maximum input length:\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oeBg48Jlvm4k"},"outputs":[],"source":["def preprocess_function(examples):\n","    return tokenizer(examples[\"text\"], truncation=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sUq2JivXvzKc"},"outputs":[],"source":["tokenized_imdb = imdb.map(preprocess_function, batched=True)"]},{"cell_type":"markdown","metadata":{"id":"HA-pjVDKv9w4"},"source":["Now create a batch of examples using DataCollatorWithPadding. It‚Äôs more efficient to dynamically pad the sentences to the longest length in a batch during collation, instead of padding the whole dataset to the maximum length.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JHZwkn0rv-DB"},"outputs":[],"source":["from transformers import DataCollatorWithPadding\n","\n","data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"]},{"cell_type":"markdown","metadata":{"id":"i4IxGv7LwL_z"},"source":["## Evaluate\n","Including a metric during training is often helpful for evaluating your model‚Äôs performance. You can quickly load a evaluation method with the ü§ó Evaluate library. For this task, load the accuracy metric (see the ü§ó Evaluate quick tour to learn more about how to load and compute a metric):"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bTYQBgvgwEvx"},"outputs":[],"source":["import evaluate\n","import numpy as np\n","\n","accuracy = evaluate.load(\"accuracy\")\n","\n","\n","\n","def compute_metrics(eval_pred):\n","    predictions, labels = eval_pred\n","    predictions = np.argmax(predictions, axis=1)\n","    return accuracy.compute(predictions=predictions, references=labels)\n","\n","id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n","label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}"]},{"cell_type":"markdown","metadata":{"id":"S2aFABJrwRKM"},"source":["## Train Your own model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jumRWY-hwEmJ"},"outputs":[],"source":["from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n","\n","model = AutoModelForSequenceClassification.from_pretrained(\n","    \"distilbert/distilbert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sm60Zo9Twi20"},"outputs":[],"source":["training_args = TrainingArguments(\n","    output_dir=\"my_awesome_model\",\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=16,\n","    num_train_epochs=2,\n","    weight_decay=0.01,\n","    eval_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    load_best_model_at_end=True,\n","    push_to_hub=True,\n",")\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_imdb[\"train\"],\n","    eval_dataset=tokenized_imdb[\"test\"],\n","    tokenizer=tokenizer,\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics,\n",")\n","\n","trainer.train()"]},{"cell_type":"markdown","metadata":{"id":"U32SIH-lwnEs"},"source":["### Inference\n","Great, now that you‚Äôve finetuned a model, you can use it for inference!\n","\n","Grab some text you‚Äôd like to run inference on:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d8PAnVE5woI7"},"outputs":[],"source":["text = \"This was a masterpiece. Not completely faithful to the books, but enthralling from beginning to end. Might be my favorite of the three.\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mPjrAbN3wzXM"},"outputs":[],"source":["from transformers import pipeline\n","\n","classifier = pipeline(\"sentiment-analysis\", model=\"stevhliu/my_awesome_model\")\n","classifier(text)"]},{"cell_type":"markdown","metadata":{"id":"6Ye6Bm4AyN40"},"source":["# Named Entery Recognition"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D6l8zYHYyP0J"},"outputs":[],"source":["from transformers import pipeline\n","\n","# create pipeline for NER\n","ner = pipeline('ner', aggregation_strategy = 'simple')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4nXE3EK_ycNN"},"outputs":[],"source":["ner(\"Hi, my name is Ganesh Lokare. I am from Pune. I want to work with Google.\")\n"]},{"cell_type":"markdown","metadata":{"id":"kEeiHgBFzjZE"},"source":["## Generative AI and Gradio"]},{"cell_type":"markdown","metadata":{"id":"DCh_fkv-3n6k"},"source":["### Image captioning app üñºÔ∏èüìù"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":245},"executionInfo":{"elapsed":5017,"status":"error","timestamp":1720689891786,"user":{"displayName":"abbas khan","userId":"07434490259532895643"},"user_tz":-300},"id":"RrrUjPMJy1Ed","outputId":"d439d4ed-ddca-4c84-ba13-d3835e5a71c1"},"outputs":[{"ename":"TypeError","evalue":"EventListener._setup.<locals>.event_trigger() got an unexpected keyword argument 'description'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-31c98af45f38>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mexamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Adventurer is approached by a mysterious stranger in the tavern for a new quest.\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m interface = gr.Interface.load(\"huggingface/pranavpsv/gpt2-genre-story-generator\",\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mexamples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: EventListener._setup.<locals>.event_trigger() got an unexpected keyword argument 'description'"]}],"source":["import gradio as gr\n","\n","description = \"Story generation with GPT-2\"\n","title = \"Generate your own story\"\n","examples = [[\"Adventurer is approached by a mysterious stranger in the tavern for a new quest.\"]]\n","\n","interface = gr.Interface.load(\"huggingface/pranavpsv/gpt2-genre-story-generator\",\n","            description=description,\n","            examples=examples\n",")\n","\n","interface.launch()\n"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":0}
