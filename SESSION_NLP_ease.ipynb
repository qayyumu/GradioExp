{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# import tensorflow as tf\n",
    "import numpy as np\n",
    "# from scipy.spatial.distance import cdist\n",
    "#!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer /huggingface library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998795986175537}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline('sentiment-analysis')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9998795986175537}]\n"
     ]
    }
   ],
   "source": [
    "result = classifier('We are happy about the course content')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment is: POSITIVE and its score: 0.9998795986175537\n"
     ]
    }
   ],
   "source": [
    "sentiment_output = result[0]['label']\n",
    "sentiment_score = result[0]['score']\n",
    "print(f'Sentiment is: {sentiment_output} and its score: {sentiment_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question-answer NLP example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad (https://huggingface.co/distilbert-base-cased-distilled-squad)\n",
      "Downloading: 100%|██████████| 473/473 [00:00<00:00, 64.9kB/s]\n",
      "Downloading: 100%|██████████| 249M/249M [02:59<00:00, 1.45MB/s] \n",
      "Downloading: 100%|██████████| 29.0/29.0 [00:00<00:00, 5.66kB/s]\n",
      "Downloading: 100%|██████████| 208k/208k [00:02<00:00, 85.0kB/s] \n",
      "Downloading: 100%|██████████| 426k/426k [00:07<00:00, 59.0kB/s] \n"
     ]
    }
   ],
   "source": [
    "question_answer = pipeline('question-answering')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.46632224321365356, 'start': 18, 'end': 41, 'answer': 'the transformer library'}\n"
     ]
    }
   ],
   "source": [
    "q_a = question_answer({\n",
    "    'question': 'Who developed this bot ?',\n",
    "    'context':'bot is created in the transformer library'\n",
    "})\n",
    "print(q_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer is the transformer library\n"
     ]
    }
   ],
   "source": [
    "print('The answer is', q_a['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarization of the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_ext = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"This is a text summary test. We are going to see in this course if the text \n",
    "can be summarize efficiently. This section of IST course is about the NLP (natural language processing). In this course of AI which brings together \n",
    "computer science and statistics to harness that predictive power. It’s a must-have skill for all aspiring data analysts and data scientists, or anyone else who wants to wrestle all that raw data into refined trends and predictions.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 142, but you input_length is only 42. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=21)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': 'This section of IST course is about the NLP (natural language processing) This is a text summary test. We are going to see in this course if the text can be summary efficiently. This section of the course is called \"Natural Language Processing\" It is about natural language processing, or NLP.'}]\n"
     ]
    }
   ],
   "source": [
    "result = summary_ext(text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in the blank document processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 570/570 [00:00<00:00, 84.9kB/s]\n",
      "Downloading: 100%|██████████| 420M/420M [04:25<00:00, 1.66MB/s]    \n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Downloading: 100%|██████████| 28.0/28.0 [00:00<00:00, 3.39kB/s]\n",
      "Downloading: 100%|██████████| 226k/226k [00:00<00:00, 251kB/s]  \n",
      "Downloading: 100%|██████████| 455k/455k [00:01<00:00, 300kB/s]  \n"
     ]
    }
   ],
   "source": [
    "mask_complete = pipeline('fill-mask',model='bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.6831169128417969,\n",
       "  'token': 1037,\n",
       "  'token_str': 'a',\n",
       "  'sequence': 'aoa, i like to develop a model.'},\n",
       " {'score': 0.08291307091712952,\n",
       "  'token': 2023,\n",
       "  'token_str': 'this',\n",
       "  'sequence': 'aoa, i like to develop this model.'},\n",
       " {'score': 0.0679972693324089,\n",
       "  'token': 1996,\n",
       "  'token_str': 'the',\n",
       "  'sequence': 'aoa, i like to develop the model.'},\n",
       " {'score': 0.05115770176053047,\n",
       "  'token': 2026,\n",
       "  'token_str': 'my',\n",
       "  'sequence': 'aoa, i like to develop my model.'},\n",
       " {'score': 0.04348995164036751,\n",
       "  'token': 2115,\n",
       "  'token_str': 'your',\n",
       "  'sequence': 'aoa, i like to develop your model.'}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_complete(\"Aoa, i like to develop [MASK] model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
