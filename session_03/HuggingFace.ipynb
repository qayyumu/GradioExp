{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/qayyumu/GradioExp/blob/main/session_03/HuggingFace.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install transformers \n",
    "!pip install python-dotenv \n",
    "!pip install requests "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import required libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline('sentiment-analysis')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = classifier('We are happy about the course content')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_output = result[0]['label']\n",
    "sentiment_score = result[0]['score']\n",
    "print(f'Sentiment is: {sentiment_output} and its score: {sentiment_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysys in urdu langage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Load the model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/muril-base-cased\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"MichaelHuang/muril_base_cased_urdu_sentiment_2.0\")\n",
    "\n",
    "\n",
    "# Define the input text\n",
    "text = '''\n",
    "لیکن مسٹر پوتن نے یہ بھی کہا کہ یہ منصوبہ اسی وقت پیش کیا جا سکتا ہے جب لوگ 'مغرب اور کیئو میں' اس کے لیے تیار ہوں۔\n",
    "روسی رہنما نے منگل کو ماسکو میں چینی صدر شی جن پنگ سے ملاقات کی جس میں روس یوکرین جنگ اور دونوں ممالک کے درمیان تعلقات پر تبادلہ خیال کیا گیا۔\n",
    "گذشتہ ماہ شائع ہونے والے چین کے منصوبے میں واضح طور پر روس سے یوکرین چھوڑنے کا مطالبہ نہیں کیا گیا ہے۔\n",
    "'''\n",
    "\n",
    "# Tokenize the input text\n",
    "inputs = tokenizer(text, return_tensors='pt')\n",
    "\n",
    "# Make a prediction\n",
    "outputs = model(**inputs)\n",
    "predicted_class = torch.argmax(outputs.logits).item()\n",
    "\n",
    "# Print the predicted class\n",
    "if predicted_class == 1:\n",
    "    print('Positive')\n",
    "else:\n",
    "    print('Negative')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question-answer NLP example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer = pipeline('question-answering')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_a = question_answer({\n",
    "    'question': 'Who developed this bot ?',\n",
    "    'context':'bot is created in the transformer library'\n",
    "})\n",
    "print(q_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The answer is', q_a['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in the blank document processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_complete = pipeline('fill-mask',model='bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_complete(\"Aoa, i like to develop [MASK] model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entery Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# create pipeline for NER\n",
    "ner = pipeline('ner', aggregation_strategy = 'simple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner(\"Hi, my name is Ganesh Lokare. I am from Pune. I want to work with Google.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
